# Data Science
 These four are the pillars of data science.
 - Calculus
 - Linear Algebra
 - Probability and Stat
 - Computer Science

Frequentist definiton of probability 

## Law of Large Numbers
 - The law of large numbers states that the more experiments we run,the closer we will tend to get the expected probability.

## Events and Sample Spaces
  - Coin Toss example
  - Dice throwing example

Sample Space - Set of all possible outcomes.

Event - Anyone of possible outcome or sample space.

P(Event) = No of favourable outcomes/Total number of outcomes

### Dependent and independent events

  - Independent event - Probability of getting head each time we toss a coin.
  - Dependent event - Throwing a die

                     P(2/Even) = 1/3
    This is known as conditional probability.
    
### Joint probability 
  is the probability of two or more events happening at the same time. It is the probability of the intersection of these events.

### Marginal probability 
  refers to the probability of a single event occurring, without consideration of any other events. It is derived from a joint probability distribution and represents the likelihood of an event happening in isolation.                                                                                                                                                       

### Conditional Probability 
- Conditional probability is the probability of an event occurring given that another event has already occurred. It is denoted as P(A|B), which reads as "the probability of event A given event B".
- P(A∣B)=P(A∩B)/P(B)
 - Similarity to hypothesis testing

### Bayes Theorem
Bayes theorem (also known as the Bayes Rule or Bayes Law) is used to determine the conditional probability of event A when event B has already occurred.
- P(A|B) = P(B|A)P(A) / P(B)
- P(Ei|A) = P(Ei)P(A|Ei) / ∑ P(Ek)P(A|Ek) for k = 1, 2, 3, …., n
   - Prior - P(A)
   - Likelihood - P(B/A)
   - Posterior - P(A/B)
   - Marginal - P(B)

### Difference between conditional probability and Bayes theorem
Conditional probability is the probability of an event occurring given that another event has already occurred.  Bayes' Theorem, extends the idea of conditional probability. It provides a way to update the probability of a hypothesis based on new evidence.

Combinotorics
 - Binomial distribution

Expected value

Essence of information theory
 - Quantifying uncertainity
 - Entropy
 - Entropy curve calculation
 - Cross entropy                                                                                                           
